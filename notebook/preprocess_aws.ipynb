{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/TaigoKuriyama/ms_malware_prediction/blob/master/notebook/preprocess_gcolab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eVLnf2wOSsav"
   },
   "source": [
    "# Microsoft Malware detection\n",
    "\n",
    "In this kernel, I build a LGBM model using only a subset of the training data, in order to fit in memory.\n",
    "\n",
    "## Notebook  Content\n",
    "1. [Utility functions](#0)\n",
    "1. [Loading the data](#1) <br>\n",
    "    2.1 [Get the files and select the variables](#2.1) <br>\n",
    "    2.2 [Define the type of each variable](#2.2)\n",
    "1. [Feature engineering](#2) <br>\n",
    "    3.1 [Frequency encoding](#3.1) <br>\n",
    "    3.2 [Label encoding](#3.2)\n",
    "1. [Training the model](#3)\n",
    "1. [Feature importance](#4)\n",
    "1. [Submission](#5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://ms-malware-prediction/train.csv to ../data/raw/train.csv\n",
      "download: s3://ms-malware-prediction/test.csv to ../data/raw/test.csv\n"
     ]
    }
   ],
   "source": [
    "! aws s3 cp s3://ms-malware-prediction/train.csv ../data/raw\n",
    "! aws s3 cp s3://ms-malware-prediction/test.csv ../data/raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtlXXGmWbUmz"
   },
   "outputs": [],
   "source": [
    "num = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xEFvq2IWMNQP"
   },
   "source": [
    "<a id=\"0\"></a> <br>\n",
    "## 1. Utility functions\n",
    "Before starting, we define a utility function that helps managing memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QB8Dad9GX7hE"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0YzB6WKSKd6"
   },
   "source": [
    "<a id=\"1\"></a> <br>\n",
    "## 2. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "j0prHJumHpk1",
    "outputId": "b584c9a8-ef8a-4111-ecee-5585ad2a5505"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import warnings\n",
    "import gc\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn import metrics\n",
    "# Plotly library\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "import plotly.graph_objs as go\n",
    "from plotly import tools\n",
    "init_notebook_mode(connected=True)\n",
    "pd.set_option('display.max_columns', 500) # display all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UH2cAGI3SPUj"
   },
   "source": [
    "<a id=\"2.1\"></a> <br>\n",
    "### 2.1 Get the files and select the variables\n",
    "Following [Theo Viel](https://www.kaggle.com/theoviel/load-the-totality-of-the-data), we set the types of each fields in the train set in order to reduce the memory usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WpOdo0uMSQfH"
   },
   "outputs": [],
   "source": [
    "dtypes = {\n",
    "        'MachineIdentifier':                                    'category',\n",
    "        'ProductName':                                          'category',\n",
    "        'EngineVersion':                                        'category',\n",
    "        'AppVersion':                                           'category',\n",
    "        'AvSigVersion':                                         'category',\n",
    "        'IsBeta':                                               'int8',\n",
    "        'RtpStateBitfield':                                     'float16',\n",
    "        'IsSxsPassiveMode':                                     'int8',\n",
    "        'DefaultBrowsersIdentifier':                            'float16',\n",
    "        'AVProductStatesIdentifier':                            'float32',\n",
    "        'AVProductsInstalled':                                  'float16',\n",
    "        'AVProductsEnabled':                                    'float16',\n",
    "        'HasTpm':                                               'int8',\n",
    "        'CountryIdentifier':                                    'int16',\n",
    "        'CityIdentifier':                                       'float32',\n",
    "        'OrganizationIdentifier':                               'float16',\n",
    "        'GeoNameIdentifier':                                    'float16',\n",
    "        'LocaleEnglishNameIdentifier':                          'int8',\n",
    "        'Platform':                                             'category',\n",
    "        'Processor':                                            'category',\n",
    "        'OsVer':                                                'category',\n",
    "        'OsBuild':                                              'int16',\n",
    "        'OsSuite':                                              'int16',\n",
    "        'OsPlatformSubRelease':                                 'category',\n",
    "        'OsBuildLab':                                           'category',\n",
    "        'SkuEdition':                                           'category',\n",
    "        'IsProtected':                                          'float16',\n",
    "        'AutoSampleOptIn':                                      'int8',\n",
    "        'PuaMode':                                              'category',\n",
    "        'SMode':                                                'float16',\n",
    "        'IeVerIdentifier':                                      'float16',\n",
    "        'SmartScreen':                                          'category',\n",
    "        'Firewall':                                             'float16',\n",
    "        'UacLuaenable':                                         'float32',\n",
    "        'Census_MDC2FormFactor':                                'category',\n",
    "        'Census_DeviceFamily':                                  'category',\n",
    "        'Census_OEMNameIdentifier':                             'float16',\n",
    "        'Census_OEMModelIdentifier':                            'float32',\n",
    "        'Census_ProcessorCoreCount':                            'float16',\n",
    "        'Census_ProcessorManufacturerIdentifier':               'float16',\n",
    "        'Census_ProcessorModelIdentifier':                      'float16',\n",
    "        'Census_ProcessorClass':                                'category',\n",
    "        'Census_PrimaryDiskTotalCapacity':                      'float32',\n",
    "        'Census_PrimaryDiskTypeName':                           'category',\n",
    "        'Census_SystemVolumeTotalCapacity':                     'float32',\n",
    "        'Census_HasOpticalDiskDrive':                           'int8',\n",
    "        'Census_TotalPhysicalRAM':                              'float32',\n",
    "        'Census_ChassisTypeName':                               'category',\n",
    "        'Census_InternalPrimaryDiagonalDisplaySizeInInches':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionHorizontal':    'float16',\n",
    "        'Census_InternalPrimaryDisplayResolutionVertical':      'float16',\n",
    "        'Census_PowerPlatformRoleName':                         'category',\n",
    "        'Census_InternalBatteryType':                           'category',\n",
    "        'Census_InternalBatteryNumberOfCharges':                'float32',\n",
    "        'Census_OSVersion':                                     'category',\n",
    "        'Census_OSArchitecture':                                'category',\n",
    "        'Census_OSBranch':                                      'category',\n",
    "        'Census_OSBuildNumber':                                 'int16',\n",
    "        'Census_OSBuildRevision':                               'int32',\n",
    "        'Census_OSEdition':                                     'category',\n",
    "        'Census_OSSkuName':                                     'category',\n",
    "        'Census_OSInstallTypeName':                             'category',\n",
    "        'Census_OSInstallLanguageIdentifier':                   'float16',\n",
    "        'Census_OSUILocaleIdentifier':                          'int16',\n",
    "        'Census_OSWUAutoUpdateOptionsName':                     'category',\n",
    "        'Census_IsPortableOperatingSystem':                     'int8',\n",
    "        'Census_GenuineStateName':                              'category',\n",
    "        'Census_ActivationChannel':                             'category',\n",
    "        'Census_IsFlightingInternal':                           'float16',\n",
    "        'Census_IsFlightsDisabled':                             'float16',\n",
    "        'Census_FlightRing':                                    'category',\n",
    "        'Census_ThresholdOptIn':                                'float16',\n",
    "        'Census_FirmwareManufacturerIdentifier':                'float16',\n",
    "        'Census_FirmwareVersionIdentifier':                     'float32',\n",
    "        'Census_IsSecureBootEnabled':                           'int8',\n",
    "        'Census_IsWIMBootEnabled':                              'float16',\n",
    "        'Census_IsVirtualDevice':                               'float16',\n",
    "        'Census_IsTouchEnabled':                                'int8',\n",
    "        'Census_IsPenCapable':                                  'int8',\n",
    "        'Census_IsAlwaysOnAlwaysConnectedCapable':              'float16',\n",
    "        'Wdft_IsGamer':                                         'float16',\n",
    "        'Wdft_RegionIdentifier':                                'float16',\n",
    "        'HasDetections':                                        'int8'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 527
    },
    "colab_type": "code",
    "id": "vi_ic--LKpH1",
    "outputId": "14f5e7ee-842a-45f1-ade7-acb47b20ef7a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Census_MDC2FormFactor',\n",
       " 'OsBuildLab',\n",
       " 'PuaMode',\n",
       " 'AvSigVersion',\n",
       " 'Census_OSWUAutoUpdateOptionsName',\n",
       " 'Census_ProcessorClass',\n",
       " 'Processor',\n",
       " 'Census_ActivationChannel',\n",
       " 'SkuEdition',\n",
       " 'Census_InternalBatteryType',\n",
       " 'OsVer',\n",
       " 'MachineIdentifier',\n",
       " 'Census_PowerPlatformRoleName',\n",
       " 'Census_ChassisTypeName',\n",
       " 'Census_PrimaryDiskTypeName',\n",
       " 'Census_OSVersion',\n",
       " 'OsPlatformSubRelease',\n",
       " 'Census_FlightRing',\n",
       " 'Census_OSArchitecture',\n",
       " 'EngineVersion',\n",
       " 'Census_GenuineStateName',\n",
       " 'SmartScreen',\n",
       " 'Platform',\n",
       " 'Census_OSInstallTypeName',\n",
       " 'Census_OSEdition',\n",
       " 'ProductName',\n",
       " 'Census_DeviceFamily',\n",
       " 'Census_OSBranch',\n",
       " 'AppVersion',\n",
       " 'Census_OSSkuName']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "numerical_columns = [c for c,v in dtypes.items() if v in numerics]\n",
    "categorical_columns = [c for c,v in dtypes.items() if v not in numerics]\n",
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "dtXfs1ULShIE",
    "outputId": "782ac3fd-6438-4f9b-9161-0672aa31d4f6"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "nrows = 1000000 # 読み込む行数を指定。trainデータのレコード数は8921482\n",
    "retained_columns = numerical_columns + categorical_columns\n",
    "train = pd.read_csv(data_dir + 'train.csv',\n",
    "                             nrows = nrows, # 読み込む行数を指定\n",
    "                              usecols = retained_columns, # 読み込むカラムを指定\n",
    "                              dtype = dtypes)\n",
    "\n",
    "retained_columns += ['MachineIdentifier']\n",
    "retained_columns.remove('HasDetections')\n",
    "test = pd.read_csv(data_dir + 'test.csv',\n",
    "                             usecols = retained_columns,\n",
    "                             dtype = dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B_p71vFrEwSL"
   },
   "outputs": [],
   "source": [
    "#各カテゴリーの出現回数を計算\n",
    "grouped_countryidentifier = train.groupby(\"CountryIdentifier\")[\"CountryIdentifier\"].count().reset_index(name='countryidentifier_counts')\n",
    "grouped_hasdetections = train.groupby(\"CountryIdentifier\")[\"HasDetections\"].sum().round().astype(int).reset_index(name='hasdetections_counts')\n",
    "\n",
    "#元のデータセットにCountryIdentifierをキーとして結合\n",
    "train = train.merge(grouped_countryidentifier, how=\"left\", on=\"CountryIdentifier\")\n",
    "train = train.merge(grouped_hasdetections, how=\"left\", on=\"CountryIdentifier\")\n",
    "test = test.merge(grouped_countryidentifier, how=\"left\", on=\"CountryIdentifier\")\n",
    "test = test.merge(grouped_hasdetections, how=\"left\", on=\"CountryIdentifier\")\n",
    "\n",
    "#計算する際に自分自身の値は除く\n",
    "train[\"target_mean_encoding\"] = (train[\"hasdetections_counts\"] - train[\"HasDetections\"])/(train[\"countryidentifier_counts\"] - 1)\n",
    "test[\"target_mean_encoding\"] = test[\"hasdetections_counts\"]/test[\"countryidentifier_counts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yURg6fh_XjII"
   },
   "outputs": [],
   "source": [
    "del grouped_countryidentifier, grouped_hasdetections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C-XfFyEeW1mz"
   },
   "source": [
    "<a id=\"2.2\"></a> <br>\n",
    "### 2.2 Define the type of each variable\n",
    "In practice, among the numerical variables, many corresponds to identifiers. *In the current dataset, the truly numerical variables are in fact rare*. Below, I make a list of the variables which are truly numerical, according the the description of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDK5L3PKzZhx"
   },
   "outputs": [],
   "source": [
    "# create new feature\n",
    "train['new_num_1'] = train['Census_TotalPhysicalRAM'] * train['Census_InternalPrimaryDiagonalDisplaySizeInInches']\n",
    "test['new_num_1'] = test['Census_TotalPhysicalRAM'] * test['Census_InternalPrimaryDiagonalDisplaySizeInInches']\n",
    "\n",
    "train['new_num_2'] = train['Census_ProcessorCoreCount'] * train['Census_InternalPrimaryDiagonalDisplaySizeInInches']\n",
    "test['new_num_2'] = test['Census_ProcessorCoreCount'] * test['Census_InternalPrimaryDiagonalDisplaySizeInInches']\n",
    "\n",
    "train['new_num_3'] = train['Census_ProcessorCoreCount'] * train['Census_TotalPhysicalRAM']\n",
    "test['new_num_3'] = test['Census_ProcessorCoreCount'] * test['Census_TotalPhysicalRAM']\n",
    "\n",
    "train['new_num_4'] = train['Census_PrimaryDiskTotalCapacity'] * train['Census_TotalPhysicalRAM']\n",
    "test['new_num_4'] = test['Census_PrimaryDiskTotalCapacity'] * test['Census_TotalPhysicalRAM']\n",
    "\n",
    "train['new_num_5'] = train['Census_SystemVolumeTotalCapacity'] * train['Census_InternalPrimaryDiagonalDisplaySizeInInches']\n",
    "test['new_num_5'] = test['Census_SystemVolumeTotalCapacity'] * test['Census_InternalPrimaryDiagonalDisplaySizeInInches']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aY6nZEFQ0KKc"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "for n in range(1, 5): # 1 to10\n",
    "    with open(data_dir + 'feature_train_{}.pickle'.format(n), 'wb') as f:\n",
    "        # Pickle the 'data' dictionary using the highest protocol available.\n",
    "        pickle.dump(train['new_num_{0}'.format(n)] , f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vqykAC1RShRq"
   },
   "outputs": [],
   "source": [
    "true_numerical_columns = [\n",
    "    'Census_ProcessorCoreCount',\n",
    "    'Census_PrimaryDiskTotalCapacity',\n",
    "    'Census_SystemVolumeTotalCapacity',\n",
    "    'Census_TotalPhysicalRAM',\n",
    "    'Census_InternalPrimaryDiagonalDisplaySizeInInches',\n",
    "    'Census_InternalPrimaryDisplayResolutionHorizontal',\n",
    "    'Census_InternalPrimaryDisplayResolutionVertical',\n",
    "    'Census_InternalBatteryNumberOfCharges'\n",
    "    'new_num_1', 'new_num_2', 'new_num_3', 'new_num_4', 'new_num_5'\n",
    "    'countryidentifier_counts', 'hasdetections_counts', 'target_mean_encoding'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCuG2utYXP9c"
   },
   "source": [
    "We also list binary variables, since they can be treated as numericals by tree methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ed-jRpRDXM8p"
   },
   "outputs": [],
   "source": [
    "# ２値のカラムを取得\n",
    "binary_variables = [c for c in train.columns if train[c].nunique() == 2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "RsBECVR2XVmk",
    "outputId": "8972223d-8051-4a34-ace3-c11c02707c06"
   },
   "outputs": [],
   "source": [
    "binary_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "nU9JiTd7ShT5",
    "outputId": "924d0206-0974-49a2-9f64-13de3aaa504a"
   },
   "outputs": [],
   "source": [
    "train[binary_variables].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqME8rMQX77n"
   },
   "source": [
    "to finally make a census of the categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qfmDHovUXjfv"
   },
   "outputs": [],
   "source": [
    "categorical_columns = [c for c in train.columns \n",
    "                       if (c not in true_numerical_columns) & (c not in binary_variables)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sxbd_rjlZlXg"
   },
   "source": [
    "Most of the current variables are categories and we need to choose a method to treat them. **Depending on the cardinality of each variable**, we can opt for** one-hot-encoding, frequency or target encoding**. In the particular case of Light-GBM, we can also use the **built-in LGBM treatment of categoricals**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ch4EgCWjaB21"
   },
   "source": [
    "<a id=\"2\"></a> <br>\n",
    "## 3. Feature Engineering\n",
    "<a id=\"3.1\"></a> <br>\n",
    "### 3.1 Frequency encoding\n",
    "For variables with large cardinality, an efficient encoding consists in ranking the categories with respect to their frequencies. These variables are then treated as numerical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cxLeRNyhZv5j"
   },
   "outputs": [],
   "source": [
    "def frequency_encoding(variable):\n",
    "    t = pd.concat([train[variable], test[variable]]).value_counts().reset_index()\n",
    "    t = t.reset_index()\n",
    "    t.loc[t[variable] == 1, 'level_0'] = np.nan\n",
    "    t.set_index('index', inplace=True)\n",
    "    max_label = t['level_0'].max() + 1\n",
    "    t.fillna(max_label, inplace=True)\n",
    "    return t.to_dict()['level_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GjROuIRnaDeB"
   },
   "outputs": [],
   "source": [
    "frequency_encoded_variables = [\n",
    "    'Census_OEMModelIdentifier',\n",
    "    'CityIdentifier',\n",
    "    'Census_FirmwareVersionIdentifier',\n",
    "    'AvSigVersion',\n",
    "    'Census_ProcessorModelIdentifier',\n",
    "    'Census_OEMNameIdentifier',\n",
    "    'DefaultBrowsersIdentifier'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1037
    },
    "colab_type": "code",
    "id": "pTOPE2L-WKpv",
    "outputId": "3369a35e-add4-4392-a8c2-005f20dc46b1"
   },
   "outputs": [],
   "source": [
    "categorical_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "txke9S16aE7u",
    "outputId": "4a439e43-e5d7-4f27-e292-5d5a430415ba"
   },
   "outputs": [],
   "source": [
    "for variable in tqdm(frequency_encoded_variables):\n",
    "    freq_enc_dict = frequency_encoding(variable)\n",
    "    train[variable] = train[variable].map(lambda x: freq_enc_dict.get(x, np.nan))\n",
    "    test[variable] = test[variable].map(lambda x: freq_enc_dict.get(x, np.nan))\n",
    "    categorical_columns.remove(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MwNgo3uZaGOV",
    "outputId": "6f46351c-2aea-49c1-d499-908ee84e8813"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 782
    },
    "colab_type": "code",
    "id": "z8DauLr1qvMA",
    "outputId": "81a08de2-d213-4bb5-e035-f29c6934b282"
   },
   "outputs": [],
   "source": [
    "# 変数のメモリ使用量を表示\n",
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\"):\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtrwMUwZasw0"
   },
   "source": [
    "<a id=\"3.2\"></a> <br>\n",
    "### 3.2 Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "haVZohpOar4Z",
    "outputId": "360a13c6-ed9d-48d1-ff05-ce766ea3d743"
   },
   "outputs": [],
   "source": [
    "indexer = {}\n",
    "for col in tqdm(categorical_columns):\n",
    "    if col == 'MachineIdentifier': continue\n",
    "    _, indexer[col] = pd.factorize(train[col])\n",
    "    \n",
    "for col in tqdm(categorical_columns):\n",
    "    if col == 'MachineIdentifier': continue\n",
    "    train[col] = indexer[col].get_indexer(train[col])\n",
    "train = reduce_mem_usage(train)\n",
    "\n",
    "for col in tqdm(categorical_columns):\n",
    "    if col == 'MachineIdentifier': continue\n",
    "    test[col] = indexer[col].get_indexer(test[col])\n",
    "test = reduce_mem_usage(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "nuPatNMaa3Km",
    "outputId": "411d6ad2-9b9b-432d-9999-60df725b4e0c"
   },
   "outputs": [],
   "source": [
    "train[:5]\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "mnpKym-pirRH",
    "outputId": "02f14590-3cc5-4c29-b6b4-671ea2e49b47"
   },
   "outputs": [],
   "source": [
    "test[:5]\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Us4hbUSNa3nr"
   },
   "source": [
    "データの保存、読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4w_d2LnunQGp"
   },
   "outputs": [],
   "source": [
    "#train.to_csv('/content/gdrive/My Drive/ms_malware_prediction/data/processed/feature_{}.csv'.format(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UkhmiwMx1z94"
   },
   "outputs": [],
   "source": [
    "#train = pd.read_csv('/content/gdrive/My Drive/ms_malware_prediction/data/processed/feature_{}.csv'.format(num) , index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ca4X_C9ma4nj"
   },
   "outputs": [],
   "source": [
    "target = train['HasDetections']\n",
    "del train['HasDetections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "wchXNoWvN8G6",
    "outputId": "11e2690d-c066-4a89-dc8e-ad0a1878c3f2"
   },
   "outputs": [],
   "source": [
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oQEl1xBmbGX_"
   },
   "source": [
    "<a id=\"3\"></a> <br>\n",
    "## 3. Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnMr-XWibFrk"
   },
   "outputs": [],
   "source": [
    "param = {'num_leaves': 60,\n",
    "         'min_data_in_leaf': 60, \n",
    "         'objective':'binary',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.1,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.8,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.8 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'auc',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WFNr5LBsbzmq"
   },
   "outputs": [],
   "source": [
    "max_iter = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "QhRhmmDub04H",
    "outputId": "454ced02-5b87-41f5-9e77-8019323b35cf"
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fg_qBUbebI7p"
   },
   "outputs": [],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train))\n",
    "categorical_columns = [c for c in categorical_columns if c not in ['MachineIdentifier']]\n",
    "features = [c for c in train.columns if c not in ['MachineIdentifier']]\n",
    "predictions = np.zeros(len(test))\n",
    "start = time.time()\n",
    "feature_importance_df = pd.DataFrame()\n",
    "start_time= time.time()\n",
    "score = [0 for _ in range(folds.n_splits)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1003
    },
    "colab_type": "code",
    "id": "EtweEoZcxlz2",
    "outputId": "7dad3b8f-bd33-49d9-fbbb-024a97ad1846"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train.iloc[trn_idx][features],\n",
    "                           label=target.iloc[trn_idx],\n",
    "                           categorical_feature = categorical_columns\n",
    "                          )\n",
    "    val_data = lgb.Dataset(train.iloc[val_idx][features],\n",
    "                           label=target.iloc[val_idx],\n",
    "                           categorical_feature = categorical_columns\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=100,\n",
    "                    early_stopping_rounds = 200)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance(importance_type='gain')\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "    # we perform predictions by chunks\n",
    "    initial_idx = 0\n",
    "    chunk_size = 1000000\n",
    "    current_pred = np.zeros(len(test))\n",
    "    while initial_idx < test.shape[0]:\n",
    "        final_idx = min(initial_idx + chunk_size, test.shape[0])\n",
    "        idx = range(initial_idx, final_idx)\n",
    "        current_pred[idx] = clf.predict(test.iloc[idx][features], num_iteration=clf.best_iteration)\n",
    "        initial_idx = final_idx\n",
    "    predictions += current_pred / min(folds.n_splits, max_iter)\n",
    "   \n",
    "    print(\"time elapsed: {:<5.2}s\".format((time.time() - start_time) / 3600))\n",
    "    score[fold_] = metrics.roc_auc_score(target.iloc[val_idx], oof[val_idx])\n",
    "    if fold_ == max_iter - 1: break\n",
    "        \n",
    "if (folds.n_splits == max_iter):\n",
    "    print(\"CV score: {:<8.5f}\".format(metrics.roc_auc_score(target, oof)))\n",
    "else:\n",
    "     print(\"CV score: {:<8.5f}\".format(sum(score) / max_iter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qViOXaSeblPv"
   },
   "source": [
    "<a id=\"4\"></a> <br>\n",
    "## 4. Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Q4zf1gZbiVD"
   },
   "outputs": [],
   "source": [
    "cols = (feature_importance_df[[\"feature\", \"importance\"]]\n",
    "           .groupby(\"feature\")\n",
    "           .mean()\n",
    "           .sort_values(by=\"importance\", ascending=False)[:1000].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "                 y=\"feature\",\n",
    "                 data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE0DELFIbpL_"
   },
   "source": [
    "<a id=\"5\"></a> <br>\n",
    "## 5. Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpwHAat2boW8"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"MachineIdentifier\": test[\"MachineIdentifier\"].values})\n",
    "sub_df[\"HasDetections\"] = predictions\n",
    "sub_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rzb7USRbvFY"
   },
   "outputs": [],
   "source": [
    "sub_df.to_csv('submit_{}.csv'.format(num), index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "preprocess_gcolab.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
